{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkw3f1P5xxyj",
    "outputId": "c37c4621-f2e3-46da-96d0-327ab201e3b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kv-foW7PAI8h"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_mGiXFgAVjr"
   },
   "outputs": [],
   "source": [
    "train_dir = (\"/content/gdrive/MyDrive/BrainStroke/Brain_Stroke_CT-SCAN_image/Train\")\n",
    "\n",
    "test_dir = (\"/content/gdrive/MyDrive/BrainStroke/Brain_Stroke_CT-SCAN_image/Test\")\n",
    "\n",
    "validation_dir = (\"/content/gdrive/MyDrive/BrainStroke/Brain_Stroke_CT-SCAN_image/Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ds02B24NAc-r"
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PkuJzSl8Afua"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FEk8d7Xsw3O",
    "outputId": "75f784f5-bccc-4773-9137-f5ffc5564e02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1843 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_Ee3KnDsz9f",
    "outputId": "49d507c5-8df8-456a-ba48-f7fbb5fe96cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 235 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMx81Wb8Akhw",
    "outputId": "b7478f36-8adc-4802-f7bd-28d7a0c70c7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 1s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 512)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14879041 (56.76 MB)\n",
      "Trainable params: 164353 (642.00 KB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet152 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Freeze the layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eToL0EKrAnLh"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEgZ4qSTyxvd",
    "outputId": "969dc10d-44e7-4a29-8528-e34da1c02092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "58/58 [==============================] - 1497s 26s/step - loss: 0.6756 - accuracy: 0.5773 - val_loss: 0.6204 - val_accuracy: 0.6681\n",
      "Epoch 2/10\n",
      "58/58 [==============================] - 1472s 25s/step - loss: 0.6579 - accuracy: 0.6099 - val_loss: 0.6382 - val_accuracy: 0.6894\n",
      "Epoch 3/10\n",
      "58/58 [==============================] - 1473s 25s/step - loss: 0.6442 - accuracy: 0.6305 - val_loss: 0.5908 - val_accuracy: 0.6809\n",
      "Epoch 4/10\n",
      "58/58 [==============================] - 1463s 25s/step - loss: 0.6160 - accuracy: 0.6663 - val_loss: 0.6131 - val_accuracy: 0.6766\n",
      "Epoch 5/10\n",
      "58/58 [==============================] - 1484s 26s/step - loss: 0.5818 - accuracy: 0.6907 - val_loss: 0.5871 - val_accuracy: 0.7064\n",
      "Epoch 6/10\n",
      "58/58 [==============================] - 1456s 25s/step - loss: 0.5817 - accuracy: 0.6945 - val_loss: 0.5301 - val_accuracy: 0.7447\n",
      "Epoch 7/10\n",
      "58/58 [==============================] - 1457s 25s/step - loss: 0.5376 - accuracy: 0.7292 - val_loss: 0.5814 - val_accuracy: 0.6723\n",
      "Epoch 8/10\n",
      "58/58 [==============================] - 1455s 25s/step - loss: 0.5391 - accuracy: 0.7092 - val_loss: 0.5564 - val_accuracy: 0.7191\n",
      "Epoch 9/10\n",
      "58/58 [==============================] - 1456s 25s/step - loss: 0.5009 - accuracy: 0.7547 - val_loss: 0.5505 - val_accuracy: 0.7277\n",
      "Epoch 10/10\n",
      "58/58 [==============================] - 1458s 25s/step - loss: 0.5201 - accuracy: 0.7390 - val_loss: 0.6320 - val_accuracy: 0.6340\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs=10, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3GXN3XPAuOM"
   },
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Q4dHcJoGAwiX",
    "outputId": "64412860-aa62-4134-c2e1-d9be0888ebcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 334s 23s/step - loss: 0.4592 - accuracy: 0.7826\n",
      "Test Loss: 0.4591868817806244\n",
      "Test Accuracy: 0.782608687877655\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HLMpD_eEA11l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "j0ehXoHkA1Z_",
    "outputId": "ac68bc45-1dd8-416a-fa3d-e858398e232c"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: conv2d_1. Existing layers are: ['input_1', 'block1_conv1', 'block1_conv2', 'block1_pool', 'block2_conv1', 'block2_conv2', 'block2_pool', 'block3_conv1', 'block3_conv2', 'block3_conv3', 'block3_pool', 'block4_conv1', 'block4_conv2', 'block4_conv3', 'block4_pool', 'block5_conv1', 'block5_conv2', 'block5_conv3', 'block5_pool', 'global_average_pooling2d', 'dense', 'dense_1', 'dense_2'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-19cb605c8c84>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m grad_model = tf.keras.models.Model(\n\u001b[1;32m     40\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv2d_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   3565\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3566\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3567\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   3568\u001b[0m                 \u001b[0;34mf\"No such layer: {name}. Existing layers are: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3569\u001b[0m                 \u001b[0;34mf\"{list(layer.name for layer in self.layers)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: conv2d_1. Existing layers are: ['input_1', 'block1_conv1', 'block1_conv2', 'block1_pool', 'block2_conv1', 'block2_conv2', 'block2_pool', 'block3_conv1', 'block3_conv2', 'block3_conv3', 'block3_pool', 'block4_conv1', 'block4_conv2', 'block4_conv3', 'block4_pool', 'block5_conv1', 'block5_conv2', 'block5_conv3', 'block5_pool', 'global_average_pooling2d', 'dense', 'dense_1', 'dense_2']."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def Affected_Area(img_path):\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "       # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply image processing operations (e.g., thresholding, morphological operations) for stroke detection\n",
    "        _, thresholded_image = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "        closed_image = cv2.morphologyEx(thresholded_image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Find contours in the closed image\n",
    "        contours, _ = cv2.findContours(closed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Create a list to store the bounding boxes\n",
    "        bounding_boxes = []\n",
    "\n",
    "        # Draw bounding boxes around the contours\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            bounding_boxes.append((x, y, x + w, y + h))\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "target_class_index = 1\n",
    "img_path = '/content/gdrive/MyDrive/BrainStroke/Brain_Stroke_CT-SCAN_image/Test/Stroke/58 (12).jpg'\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (img_width, img_height))\n",
    "img = np.expand_dims(img, axis=0) / 255.0\n",
    "grad_model = tf.keras.models.Model(\n",
    "    [model.inputs],\n",
    "    [model.get_layer('conv2d_1').output, model.output]\n",
    ")\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(img)\n",
    "    loss = predictions[:, 0]  # Select the first (and only) element along the second dimension\n",
    "\n",
    "grads = tape.gradient(loss, conv_outputs)[0]\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs[0]), axis=-1)\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "heatmap = cv2.resize(heatmap, (img.shape[2], img.shape[1]))\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "\n",
    "superimposed_img = cv2.addWeighted(\n",
    "    np.uint8(255 * img[0]),\n",
    "    0.6,\n",
    "    np.uint8(heatmap),\n",
    "    0.4,\n",
    "    0\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(img[0])\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "predicted_class = model.predict(img)\n",
    "predicted_class_index = int(predicted_class[0] >= 0.5)  # Get the index of the predicted class\n",
    "class_names = ['No Stroke', 'Stroke']  # Define the class names\n",
    "print('Class',predicted_class_index)\n",
    "\n",
    "\n",
    "if predicted_class_index == 1:\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.title(f'Predicted Class: {class_names[predicted_class_index]}')  # Use the predicted class index to get the class name\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(heatmap)\n",
    "    plt.title('Grad-CAM Heatmap')\n",
    "    plt.axis('off')\n",
    "\n",
    "    Stroke_Affected = Affected_Area(img_path)\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(Stroke_Affected)\n",
    "    plt.title('Affected Part')\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(img[0])\n",
    "    plt.title(f'Predicted Class: {class_names[predicted_class_index]}')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "Hp5kW-IZBCj1",
    "outputId": "60f719dd-3615-41f2-801a-f24a2d9cf405"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 437 images belonging to 2 classes.\n",
      "14/14 [==============================] - 300s 21s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Rest of the code...\n",
    "\n",
    "# Step 4: Model Evaluation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred = np.round(y_pred).flatten()\n",
    "y_true = test_generator.classes\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "label_names = ['Normal', 'Stroke']  # Replace with your class labels\n",
    "beingsaved = plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xticks(np.arange(len(label_names)) + 0.5, label_names)\n",
    "plt.yticks(np.arange(len(label_names)) + 0.5, label_names)\n",
    "plt.xlabel('Predicted Labels',fontsize=12)\n",
    "plt.ylabel('True Labels',fontsize=12)\n",
    "plt.title('Confusion Matrix')\n",
    "beingsaved.savefig('Stroke_Confusion_Matrix.png', format='png', dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 Score:', f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HgXwdeTBNwD"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def Affected_Area(img_path):\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply image processing operations (e.g., thresholding, morphological operations) for stroke detection\n",
    "    _, thresholded_image = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    closed_image = cv2.morphologyEx(thresholded_image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours in the closed image\n",
    "    contours, _ = cv2.findContours(closed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a list to store the bounding boxes\n",
    "    bounding_boxes = []\n",
    "\n",
    "    # Draw bounding boxes around the contours\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        bounding_boxes.append((x, y, x + w, y + h))\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "target_class_index = 1\n",
    "img_path = '/kaggle/input/brain-stroke-prediction-ct-scan-image-dataset/Brain_Stroke_CT-SCAN_image/Test/Stroke/58 (12).jpg'\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (img_width, img_height))\n",
    "img = np.expand_dims(img, axis=0) / 255.0\n",
    "grad_model = tf.keras.models.Model(\n",
    "    [model.inputs],\n",
    "    [model.get_layer('conv2d_1').output, model.output]\n",
    ")\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(img)\n",
    "    loss = predictions[:, 0]  # Select the first (and only) element along the second dimension\n",
    "\n",
    "grads = tape.gradient(loss, conv_outputs)[0]\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs[0]), axis=-1)\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "max_heatmap = np.max(heatmap)\n",
    "if max_heatmap != 0:\n",
    "    heatmap /= max_heatmap\n",
    "heatmap = cv2.resize(heatmap, (img.shape[2], img.shape[1]))\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "superimposed_img = cv2.addWeighted(\n",
    "    np.uint8(255 * img[0]),\n",
    "    0.6,\n",
    "    np.uint8(heatmap),\n",
    "    0.4,\n",
    "    0\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(img[0])\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "predicted_class = model.predict(img)\n",
    "predicted_class_index = int(predicted_class[0] >= 0.5)  # Get the index of the predicted class\n",
    "class_names = ['No Stroke', 'Stroke']  # Define the class names\n",
    "print('Class', predicted_class_index)\n",
    "\n",
    "if predicted_class_index == 1:\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.title(f'Predicted Class: {class_names[predicted_class_index]}')  # Use the predicted class index to get the class name\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(heatmap)\n",
    "    plt.title('Grad-CAM Heatmap')\n",
    "    plt.axis('off')\n",
    "\n",
    "    Stroke_Affected = Affected_Area(img_path)\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(Stroke_Affected)\n",
    "    plt.title('Affected Part')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(img[0])\n",
    "    plt.title(f'Predicted Class: {class_names[predicted_class_index]}')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4VhZ_EUzBXy-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Affected_Area(img_path):\n",
    "    image = cv2.imread(img_path)\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply image processing operations (e.g., thresholding, morphological operations) for stroke detection\n",
    "    _, thresholded_image = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    closed_image = cv2.morphologyEx(thresholded_image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours in the closed image\n",
    "    contours, _ = cv2.findContours(closed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a list to store the bounding boxes\n",
    "    bounding_boxes = []\n",
    "\n",
    "    # Draw bounding boxes around the contours\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        bounding_boxes.append((x, y, x + w, y + h))\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "target_class_index = 1\n",
    "img_path = '/kaggle/input/brain-stroke-prediction-ct-scan-image-dataset/Brain_Stroke_CT-SCAN_image/Test/Stroke/58 (12).jpg'\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (img_width, img_height))\n",
    "img = np.expand_dims(img, axis=0) / 255.0\n",
    "\n",
    "grad_model = tf.keras.models.Model(\n",
    "    [model.inputs],\n",
    "    [model.get_layer('conv2d').output, model.output]  # Modify 'conv2d_1' to match the actual layer name\n",
    ")\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    conv_outputs, predictions = grad_model(img)\n",
    "    loss = predictions[:, 0]  # Select the first (and only) element along the second dimension\n",
    "\n",
    "grads = tape.gradient(loss, conv_outputs)[0]\n",
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs[0]), axis=-1)\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "\n",
    "heatmap = cv2.resize(heatmap, (img.shape[2], img.shape[1]))\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "\n",
    "superimposed_img = cv2.addWeighted(\n",
    "    np.uint8(255 * img[0]),\n",
    "    0.6,\n",
    "    np.uint8(heatmap),\n",
    "    0.4,\n",
    "    0\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(img[0])\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "predicted_class = model.predict(img)\n",
    "predicted_class_index = int(predicted_class[0] >= 0.5)  # Get the index of the predicted class\n",
    "class_names = ['No Stroke', 'Stroke']  # Define the class names\n",
    "\n",
    "if predicted_class_index == 1:\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.title(f'Predicted Class: {class_names[predicted_class_index]}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(heatmap)\n",
    "    plt.title('Grad-CAM Heatmap')\n",
    "    plt.axis('off')\n",
    "\n",
    "    Stroke_Affected = Affected_Area(img_path)\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(Stroke_Affected)\n",
    "    plt.title('Affected Area')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(img[0])\n",
    "    plt.title(f'Predicted Class: {class_names[predicted_class_index]}')\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
